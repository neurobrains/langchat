---
title: Getting Started
description: Get up and running with LangChat in minutes. Welcome! This guide will help you build your first LangChat application in just a few minutes.
---

import { Card, CardGroup } from 'mintlify';
import { Callout } from 'mintlify';

## Prerequisites

Before you begin, make sure you have:

- **Python 3.8+** installed
- **OpenAI API Key(s)** - Get one at [platform.openai.com](https://platform.openai.com)
- **Pinecone Account** - Sign up at [pinecone.io](https://www.pinecone.io)
- **Supabase Project** - Create one at [supabase.com](https://supabase.com)

<Callout type="info">
You can use multiple OpenAI API keys for automatic rotation and better fault tolerance.
</Callout>

## Quick Start (5 Minutes)

### Step 1: Install LangChat

Install LangChat using pip:

```bash
pip install langchat
```

Or install from source:

```bash
git clone https://github.com/neurobrains/langchat.git
cd langchat
pip install -e .
```

### Step 2: Configure Your Environment

Create a `.env` file or set environment variables:

```bash
export OPENAI_API_KEYS="your-key-1,your-key-2"  # Multiple keys for rotation
export PINECONE_API_KEY="your-pinecone-key"
export PINECONE_INDEX_NAME="your-index-name"
export SUPABASE_URL="https://your-project.supabase.co"
export SUPABASE_KEY="your-supabase-key"
```

<Callout type="warning">
Make sure your Pinecone index is already created and your Supabase project is set up.
</Callout>

### Step 3: Write Your First Chatbot

Create a file `main.py`:

```python
import asyncio
from langchat import LangChat, LangChatConfig

async def main():
    # Load configuration from environment variables
    config = LangChatConfig.from_env()
    
    # Initialize LangChat
    langchat = LangChat(config=config)
    
    # Chat with the AI
    result = await langchat.chat(
        query="Hello! What can you help me with?",
        user_id="user123",
        domain="general"
    )
    
    print(f"Response: {result['response']}")
    print(f"Status: {result['status']}")
    print(f"Response Time: {result.get('response_time', 0):.2f}s")

if __name__ == "__main__":
    asyncio.run(main())
```

### Step 4: Run It!

```bash
python main.py
```

<Callout type="success">
ðŸŽ‰ Congratulations! You just built your first LangChat application!
</Callout>

## Using LangChat as an API Server

LangChat can also run as a FastAPI server with an auto-generated frontend interface.

### Create API Server

Create `server.py`:

```python
from langchat.api.app import create_app
from langchat.config import LangChatConfig
import uvicorn

# Create configuration
config = LangChatConfig.from_env()

# Create FastAPI app (auto-generates interface and Dockerfile)
app = create_app(
    config=config,
    auto_generate_interface=True,
    auto_generate_docker=True
)

if __name__ == "__main__":
    print(f"ðŸš€ Starting LangChat API server on port {config.server_port}")
    print(f"ðŸ“± Chat interface: http://localhost:{config.server_port}/frontend")
    print(f"ðŸ“¡ API endpoint: http://localhost:{config.server_port}/chat")
    uvicorn.run(app, host="0.0.0.0", port=config.server_port)
```

### Run the Server

```bash
python server.py
```

Now you can:

- **Frontend Interface**: Visit `http://localhost:8000/frontend`
- **API Endpoint**: POST to `http://localhost:8000/chat`
- **Health Check**: GET `http://localhost:8000/health`

## Configuration Options

LangChat supports configuration in multiple ways:

### 1. Environment Variables (Recommended)

```python
config = LangChatConfig.from_env()
```

### 2. Direct Configuration

```python
config = LangChatConfig(
    openai_api_keys=["sk-...", "sk-..."],
    openai_model="gpt-4o-mini",
    openai_temperature=1.0,
    pinecone_api_key="pcsk-...",
    pinecone_index_name="my-index",
    supabase_url="https://xxxxx.supabase.co",
    supabase_key="eyJhbGc...",
    server_port=8000
)
```

### 3. Hybrid Approach

```python
config = LangChatConfig.from_env()
# Override specific settings
config.openai_model = "gpt-4"
config.server_port = 8080
```

<CardGroup cols={2}>
  <Card
    title="Configuration Guide"
    icon="gear"
    href="/guides/configuration"
  >
    Learn about all configuration options
  </Card>
  <Card
    title="Custom Prompts"
    icon="comments"
    href="/guides/prompts"
  >
    Customize your chatbot's behavior
  </Card>
</CardGroup>

## What Happens Under the Hood?

When you initialize LangChat, it automatically:

1. **Initializes Adapters**: Sets up OpenAI, Pinecone, Supabase, and Flashrank
2. **Creates Database Tables**: Sets up chat history, metrics, and feedback tables
3. **Downloads Reranker Models**: Automatically downloads Flashrank reranker models
4. **Sets Up Sessions**: Prepares user session management

<Callout type="info">
All initialization happens automatically - you don't need to configure each component separately!
</Callout>

## Next Steps

Now that you have LangChat running, explore these topics:

- **[Configuration Guide](/guides/configuration)** - Customize LangChat for your needs
- **[Custom Prompts](/guides/prompts)** - Make your chatbot unique
- **[API Reference](/reference/langchat)** - Learn about all available methods
- **[Examples](/examples/basic-usage)** - See more complex use cases

## Common Issues

### Issue: "Supabase URL and key must be provided"

**Solution**: Make sure you've set `SUPABASE_URL` and `SUPABASE_KEY` environment variables.

### Issue: "Pinecone index name must be provided"

**Solution**: Create a Pinecone index first, then set `PINECONE_INDEX_NAME`.

### Issue: "OpenAI API keys must be provided"

**Solution**: Set `OPENAI_API_KEYS` or `OPENAI_API_KEY` environment variable.

### Issue: Reranker model download fails

**Solution**: The reranker model is downloaded automatically to `rerank_models/`. Make sure you have write permissions.

## Need Help?

- Check our [Troubleshooting Guide](/advanced/troubleshooting)
- Open an issue on [GitHub](https://github.com/neurobrains/langchat/issues)
- Review the [API Reference](/reference/langchat)

---

Ready to build something amazing? Let's continue with [Configuration](/guides/configuration)!

