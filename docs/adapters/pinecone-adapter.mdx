---
title: Pinecone Adapter
description: Pinecone vector database integration for semantic search. The Pinecone Adapter provides seamless integration with Pinecone vector database for semantic search and document retrieval.
---

import { Param } from 'mintlify';

## Overview

The `PineconeVectorAdapter` wraps Pinecone's vector database functionality, providing:

- **Vector Storage**: Store and retrieve document embeddings
- **Semantic Search**: Find similar documents using cosine similarity
- **Embedding Generation**: Automatic embedding generation with OpenAI
- **LangChain Integration**: Full compatibility with LangChain's retrieval chains

## Configuration

Configure through `LangChatConfig`:

```python
from langchat.config import LangChatConfig

config = LangChatConfig(
    pinecone_api_key="pcsk-...",
    pinecone_index_name="my-index",
    openai_embedding_model="text-embedding-3-large",
    retrieval_k=5  # Number of documents to retrieve
)
```

## Usage

### Basic Usage

The adapter is automatically initialized by `LangChatEngine`:

```python
from langchat import LangChat, LangChatConfig

config = LangChatConfig(
    pinecone_api_key="pcsk-...",
    pinecone_index_name="my-index",
    openai_api_keys=["sk-..."],
    # ... other config
)

langchat = LangChat(config=config)
# Adapter is automatically initialized
```

## API Reference

### Class: `PineconeVectorAdapter`

#### Constructor

```python
PineconeVectorAdapter(
    api_key: str,
    index_name: str,
    embedding_model: str = "text-embedding-3-large",
    embedding_api_key: Optional[str] = None
)
```

#### Methods

##### `get_retriever(k: int = 5)`

Get a LangChain retriever from the vector store.

**Parameters:**

<Param name="k" type="int" default="5">
  Number of documents to retrieve
</Param>

**Returns:**
- `Retriever`: LangChain retriever instance

## Related Documentation

- **[Vector Search Guide](/guides/vector-search)** - Vector search guide
- **[Configuration](/guides/configuration)** - Configuration options

